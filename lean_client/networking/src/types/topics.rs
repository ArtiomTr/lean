use std::{collections::HashSet, fmt};

use containers::{ForkDigest, SubnetId};
use libp2p::gossipsub::{IdentTopic as Topic, TopicHash};
use serde::{Deserialize, Serialize};
// use types::{
//     altair::consts::SyncCommitteeSubnetCount,
//     config::Config as ChainConfig,
//     nonstandard::Phase,
//     phase0::{
//         consts::AttestationSubnetCount,
//         primitives::{ForkDigest, SubnetId},
//     },
// };

use crate::Subnet;

/// The gossipsub topic names.
// These constants form a topic name of the form /TOPIC_PREFIX/FORK_DIGEST/TOPIC/ENCODING_POSTFIX
// For example /leanconsensus/devnet0/blocks/ssz_snappy
pub const TOPIC_PREFIX: &str = "leanconsensus";
pub const SSZ_SNAPPY_ENCODING_POSTFIX: &str = "ssz_snappy";
pub const BLOCK_TOPIC: &str = "blocks";
pub const ATTESTATION_PREFIX: &str = "attestation";
pub const AGGREGATED_ATTESTATION_TOPIC: &str = "aggregation";

/// Returns all the topics the node should subscribe. Currently for simplicity
/// this doesn't accept phase, config or other configurations, and just returns
/// static list of topics to subscribe.
pub fn core_topics_to_subscribe() -> Vec<GossipKind> {
    vec![GossipKind::Block, GossipKind::Attestation(0)]
}

/// Returns true if a given non-core `GossipTopic` MAY be subscribe at this fork.
///
/// For example: the `Attestation` topic is not subscribed as a core topic if
/// subscribe_all_subnets = false` but we may subscribe to it outside of a fork
/// boundary if the node is an aggregator.
pub fn is_fork_non_core_topic(topic: &GossipTopic) -> bool {
    match topic.kind() {
        // Node may be aggregator of attestation topic for all known forks
        GossipKind::Attestation(_) => true,
        _ => false,
    }
}

pub fn all_topics_at_fork() -> Vec<GossipKind> {
    // // Compute the worst case of all forks
    // let sampling_subnets = HashSet::from_iter(0..chain_config.data_column_sidecar_subnet_count);
    // let opts = TopicConfig {
    //     enable_light_client_server: true,
    //     subscribe_all_subnets: true,
    //     subscribe_all_data_column_subnets: true,
    //     sampling_subnets,
    // };
    // core_topics_to_subscribe(chain_config, current_phase, &opts)
    core_topics_to_subscribe()
}

/// A gossipsub topic which encapsulates the type of messages that should be sent and received over
/// the pubsub protocol and the way the messages should be encoded.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct GossipTopic {
    /// The encoding of the topic.
    encoding: GossipEncoding,
    /// The fork digest of the topic,
    pub fork_digest: ForkDigest,
    /// The kind of topic.
    kind: GossipKind,
}

/// Enum that brings these topics into the rust type system.
// NOTE: There is intentionally no unknown type here. We only allow known gossipsub topics.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub enum GossipKind {
    /// Topic for publishing blocks.
    Block,
    /// Topic for publishing raw attestations on a particular subnet.
    Attestation(SubnetId),
    /// Topic for publishing aggregated attestations.
    AggregatedAttestation,
}

impl fmt::Display for GossipKind {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::Block => f.write_str(BLOCK_TOPIC),
            Self::Attestation(subnet) => write!(f, "{}_{}", ATTESTATION_PREFIX, subnet),
            Self::AggregatedAttestation => f.write_str(AGGREGATED_ATTESTATION_TOPIC),
        }
    }
}

/// The known encoding types for gossipsub messages.
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq, Hash, Default)]
pub enum GossipEncoding {
    /// Messages are encoded with SSZSnappy.
    #[default]
    SSZSnappy,
}

impl GossipTopic {
    pub fn new(kind: GossipKind, encoding: GossipEncoding, fork_digest: ForkDigest) -> Self {
        GossipTopic {
            encoding,
            fork_digest,
            kind,
        }
    }

    /// Returns the encoding type for the gossipsub topic.
    pub fn encoding(&self) -> &GossipEncoding {
        &self.encoding
    }

    /// Returns a mutable reference to the fork digest of the gossipsub topic.
    pub fn digest(&mut self) -> &mut ForkDigest {
        &mut self.fork_digest
    }

    /// Returns the kind of message expected on the gossipsub topic.
    pub fn kind(&self) -> &GossipKind {
        &self.kind
    }

    pub fn decode(topic: &str) -> Result<Self, String> {
        let topic_parts: Vec<&str> = topic.split('/').collect();
        if topic_parts.len() == 5 && topic_parts[1] == TOPIC_PREFIX {
            let fork_digest: ForkDigest = topic_parts[2]
                .parse()
                .map_err(|err| format!("Could not decode fork_digest: {err:?}"))?;

            let encoding = match topic_parts[4] {
                SSZ_SNAPPY_ENCODING_POSTFIX => GossipEncoding::SSZSnappy,
                _ => return Err(format!("Unknown encoding: {}", topic)),
            };
            let kind = match topic_parts[3] {
                BLOCK_TOPIC => GossipKind::Block,
                AGGREGATED_ATTESTATION_TOPIC => GossipKind::AggregatedAttestation,

                topic => match subnet_topic_index(topic) {
                    Some(kind) => kind,
                    None => return Err(format!("Unknown topic: {}", topic)),
                },
            };

            return Ok(GossipTopic {
                encoding,
                fork_digest,
                kind,
            });
        }

        Err(format!("Unknown topic: {}", topic))
    }

    pub fn subnet_id(&self) -> Option<Subnet> {
        match self.kind() {
            GossipKind::Attestation(subnet_id) => Some(Subnet::Attestation(*subnet_id)),
            _ => None,
        }
    }
}

impl From<GossipTopic> for Topic {
    fn from(topic: GossipTopic) -> Topic {
        Topic::new(topic)
    }
}

impl From<GossipTopic> for String {
    fn from(topic: GossipTopic) -> String {
        // Use the `Display` implementation below.
        topic.to_string()
    }
}

impl fmt::Display for GossipTopic {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let encoding = match self.encoding {
            GossipEncoding::SSZSnappy => SSZ_SNAPPY_ENCODING_POSTFIX,
        };

        write!(
            f,
            "/{}/{}/{}/{}",
            TOPIC_PREFIX, self.fork_digest, self.kind, encoding
        )
    }
}

impl From<Subnet> for GossipKind {
    fn from(subnet_id: Subnet) -> Self {
        match subnet_id {
            Subnet::Attestation(s) => GossipKind::Attestation(s),
        }
    }
}

// helper functions

/// Get subnet id from an attestation subnet topic hash.
pub fn subnet_from_topic_hash(topic_hash: &TopicHash) -> Option<Subnet> {
    GossipTopic::decode(topic_hash.as_str()).ok()?.subnet_id()
}

// Determines if the topic name is of an indexed topic.
fn subnet_topic_index(topic: &str) -> Option<GossipKind> {
    if let Some(index) = topic.strip_prefix(ATTESTATION_PREFIX) {
        return Some(GossipKind::Attestation(index.parse::<SubnetId>().ok()?));
    }
    None
}

// #[cfg(test)]
// mod tests {
//     use enum_iterator::Sequence;
//     use types::phase0::primitives::H32;

//     use super::GossipKind::*;
//     use super::*;

//     const GOOD_FORK_DIGEST: &str = "e1925f3b";
//     const BAD_PREFIX: &str = "tezos";
//     const BAD_FORK_DIGEST: &str = "e1925f3b4b";
//     const BAD_ENCODING: &str = "rlp";
//     const BAD_KIND: &str = "blocks";

//     fn topics() -> Vec<String> {
//         let mut topics = Vec::new();
//         let fork_digest: ForkDigest = H32([1, 2, 3, 4]);
//         for encoding in [GossipEncoding::SSZSnappy].iter() {
//             for kind in [
//                 BeaconBlock,
//                 BeaconAggregateAndProof,
//                 SignedContributionAndProof,
//                 Attestation(42),
//                 SyncCommitteeMessage(42),
//                 VoluntaryExit,
//                 ProposerSlashing,
//                 AttesterSlashing,
//             ]
//             .iter()
//             {
//                 topics.push(GossipTopic::new(kind.clone(), encoding.clone(), fork_digest).into());
//             }
//         }
//         topics
//     }

//     fn create_topic(prefix: &str, fork_digest: &str, kind: &str, encoding: &str) -> String {
//         format!("/{}/{}/{}/{}", prefix, fork_digest, kind, encoding)
//     }

//     #[test]
//     fn test_decode() {
//         for topic in topics().iter() {
//             assert!(GossipTopic::decode(topic.as_str()).is_ok());
//         }
//     }

//     #[test]
//     fn test_decode_malicious() {
//         let bad_prefix_str = create_topic(
//             BAD_PREFIX,
//             GOOD_FORK_DIGEST,
//             BEACON_BLOCK_TOPIC,
//             SSZ_SNAPPY_ENCODING_POSTFIX,
//         );
//         assert!(GossipTopic::decode(bad_prefix_str.as_str()).is_err());

//         let bad_digest_str = create_topic(
//             TOPIC_PREFIX,
//             BAD_FORK_DIGEST,
//             BEACON_BLOCK_TOPIC,
//             SSZ_SNAPPY_ENCODING_POSTFIX,
//         );
//         assert!(GossipTopic::decode(bad_digest_str.as_str()).is_err());

//         let bad_kind_str = create_topic(
//             TOPIC_PREFIX,
//             GOOD_FORK_DIGEST,
//             BAD_KIND,
//             SSZ_SNAPPY_ENCODING_POSTFIX,
//         );
//         assert!(GossipTopic::decode(bad_kind_str.as_str()).is_err());

//         let bad_encoding_str = create_topic(
//             TOPIC_PREFIX,
//             GOOD_FORK_DIGEST,
//             BEACON_BLOCK_TOPIC,
//             BAD_ENCODING,
//         );
//         assert!(GossipTopic::decode(bad_encoding_str.as_str()).is_err());

//         // Extra parts
//         assert!(
//             GossipTopic::decode("/eth2/e1925f3b/beacon_block/ssz_snappy/yolo").is_err(),
//             "should have exactly 5 parts"
//         );
//         // Empty string
//         assert!(GossipTopic::decode("").is_err());
//         // Empty parts
//         assert!(GossipTopic::decode("////").is_err());
//     }

//     #[test]
//     fn test_subnet_from_topic_hash() {
//         let topic_hash = TopicHash::from_raw("/eth2/e1925f3b/beacon_block/ssz_snappy");
//         assert!(subnet_from_topic_hash(&topic_hash).is_none());

//         let topic_hash = TopicHash::from_raw("/eth2/e1925f3b/beacon_attestation_42/ssz_snappy");
//         assert_eq!(
//             subnet_from_topic_hash(&topic_hash),
//             Some(Subnet::Attestation(42))
//         );

//         let topic_hash = TopicHash::from_raw("/eth2/e1925f3b/sync_committee_42/ssz_snappy");
//         assert_eq!(
//             subnet_from_topic_hash(&topic_hash),
//             Some(Subnet::SyncCommittee(42))
//         );
//     }

//     #[test]
//     fn test_as_str_ref() {
//         assert_eq!("beacon_block", BeaconBlock.as_ref());
//         assert_eq!(
//             "beacon_aggregate_and_proof",
//             BeaconAggregateAndProof.as_ref()
//         );
//         assert_eq!("beacon_attestation", Attestation(42).as_ref());

//         assert_eq!("sync_committee", SyncCommitteeMessage(42).as_ref());
//         assert_eq!("voluntary_exit", VoluntaryExit.as_ref());
//         assert_eq!("proposer_slashing", ProposerSlashing.as_ref());
//         assert_eq!("attester_slashing", AttesterSlashing.as_ref());
//     }

//     fn get_chain_config() -> ChainConfig {
//         let mut config = ChainConfig::default();
//         config.altair_fork_epoch = 1;
//         config.bellatrix_fork_epoch = 2;
//         config.capella_fork_epoch = 3;
//         config.deneb_fork_epoch = 4;
//         config.electra_fork_epoch = 5;
//         config.fulu_fork_epoch = 6;
//         config
//     }

//     fn get_sampling_subnets() -> HashSet<SubnetId> {
//         HashSet::new()
//     }

//     fn get_topic_config(sampling_subnets: HashSet<SubnetId>) -> TopicConfig {
//         TopicConfig {
//             enable_light_client_server: false,
//             subscribe_all_subnets: false,
//             subscribe_all_data_column_subnets: false,
//             sampling_subnets,
//         }
//     }

//     #[test]
//     fn base_topics_are_always_active() {
//         let config = get_chain_config();
//         let s = get_sampling_subnets();
//         let topic_config = get_topic_config(s);
//         for phase in enum_iterator::all() {
//             assert!(
//                 core_topics_to_subscribe(&config, phase, &topic_config)
//                     .contains(&GossipKind::BeaconBlock)
//             );
//         }
//     }

//     #[test]
//     fn blobs_are_not_subscribed_in_peerdas() {
//         let config = get_chain_config();
//         let s = get_sampling_subnets();
//         let topic_config = get_topic_config(s);
//         assert!(
//             !core_topics_to_subscribe(&config, Phase::Fulu, &topic_config)
//                 .contains(&GossipKind::BlobSidecar(0))
//         );
//     }

//     #[test]
//     fn columns_are_subscribed_in_peerdas() {
//         let config = get_chain_config();
//         let s = get_sampling_subnets();
//         let mut topic_config = get_topic_config(s);
//         topic_config.subscribe_all_data_column_subnets = true;
//         assert!(
//             core_topics_to_subscribe(&config, Phase::Fulu, &topic_config)
//                 .contains(&GossipKind::DataColumnSidecar(0 as SubnetId))
//         )
//     }

//     #[test]
//     fn test_core_topics_to_subscribe() {
//         let config = get_chain_config();
//         let s = HashSet::from_iter([1, 2].map(|s| s as SubnetId));
//         let mut topic_config = get_topic_config(s.clone());
//         topic_config.enable_light_client_server = true;
//         let latest_fork = Phase::last().unwrap_or(Phase::Phase0);
//         let topics = core_topics_to_subscribe(&config, latest_fork, &topic_config);

//         let mut expected_topics = vec![
//             GossipKind::BeaconBlock,
//             GossipKind::BeaconAggregateAndProof,
//             GossipKind::VoluntaryExit,
//             GossipKind::ProposerSlashing,
//             GossipKind::AttesterSlashing,
//             GossipKind::SignedContributionAndProof,
//             GossipKind::LightClientFinalityUpdate,
//             GossipKind::LightClientOptimisticUpdate,
//             GossipKind::BlsToExecutionChange,
//         ];
//         for subnet in s {
//             expected_topics.push(GossipKind::DataColumnSidecar(subnet));
//         }
//         // Need to check all the topics exist in an order independent manner
//         for expected_topic in expected_topics {
//             assert!(
//                 topics.contains(&expected_topic),
//                 "Should contain {:?}",
//                 expected_topic,
//             );
//         }
//     }
// }
